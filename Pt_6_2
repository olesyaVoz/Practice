import scrapy
from scrapy.crawler import CrawlerProcess

class SteamSpider(scrapy.Spider):
    name = "steam_spider"
    start_urls = ["https://store.steampowered.com/search/?category1=998&filter=topsellers&ndl=1&page=%s"]
    game_count = 0


    def parse(self, response):
        for link in response.css('div.search_results a::attr(href)'):
            yield response.follow(link, callback = self.parse_tags)
            page = 1
            self.game_count += 1
            for page in range(1, 45):
                if self.game_count < 1000:
                    next_page = f"https://store.steampowered.com/search/?filter=topsellers&page={page}"
                    yield response.follow(next_page, callback = self.parse)
    
    def parse_tags(self, response):
            yield {
                'name': response.css("div.apphub_AppName::text").get(),
                'tags': list(map(str.strip, response.css(".app_tag::text").getall()))
            }
        
if __name__ == "__main__":
        process = CrawlerProcess(
        settings={
            "FEEDS": {
                "steam_tags.csv": {"format": "csv"},
            },
        }
    )


process.crawl(SteamSpider)
process.start()